{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41700ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "src_path = kagglehub.dataset_download(\"tawsifurrahman/covid19-radiography-database\")\n",
    "print(\"Original path:\", src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51472f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"\" # Change this to your local path or Google Drive mount path if running in Colab !!!\n",
    "              # if you keep DATA_DIR = \"\" , the data will be loaded in your current repo !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc93915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "source_root = Path(src_path+'/COVID-19_Radiography_Dataset')\n",
    "target_root = Path(DATA_DIR + \"/data_for_split\")\n",
    "\n",
    "# Class folders\n",
    "classes = [\"COVID\", \"Normal\", \"Lung_Opacity\", \"Viral Pneumonia\"]\n",
    "\n",
    "# Create image-only dataset\n",
    "for cls in classes:\n",
    "    source = source_root / cls / \"images\"\n",
    "    target = target_root / cls\n",
    "    target.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file in source.glob(\"*.*\"):\n",
    "        shutil.copy(file, target)\n",
    "\n",
    "print(\"âœ… Images copied successfully to\", target_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!%pip install split-folders\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "base_dir = f\"{DATA_DIR}/dataset\"\n",
    "\n",
    "splitfolders.ratio(\n",
    "    f\"{DATA_DIR}/data_for_split\",\n",
    "    output=base_dir,\n",
    "    seed=42,\n",
    "    ratio=(.7, .2, .1),  # train, val, test\n",
    "    group_prefix=None  # Only needed for paired data like images + masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd108b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = base_dir + \"/train\"\n",
    "dispaly_data_distribuation(train_path)  # Display the distribution of images across classes in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d3552",
   "metadata": {},
   "source": [
    "As you can see , there is a huge imbalance between the classes .So ,in the next cell we will apply data augmentation to resolve this problem !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "train_dir = base_dir + \"/train\"\n",
    "aug_dir = base_dir + \"/train_augmented\"\n",
    "classes_to_augment = ['COVID', 'Lung_Opacity', 'Viral Pneumonia']\n",
    "\n",
    "# Create augmentation generator\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Copy all original images to the new folder\n",
    "for cls in os.listdir(train_dir):\n",
    "    src = os.path.join(train_dir, cls)\n",
    "    dst = os.path.join(aug_dir, cls)\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "\n",
    "    for img_name in os.listdir(src):\n",
    "        shutil.copy(os.path.join(src, img_name), os.path.join(dst, img_name))\n",
    "\n",
    "        # Augment only if class is in the selected list\n",
    "        if cls in classes_to_augment:\n",
    "            img = load_img(os.path.join(src, img_name))\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            # Create 3 augmented versions\n",
    "            for i, batch in enumerate(augmenter.flow(x, batch_size=1,\n",
    "                                                     save_to_dir=dst,\n",
    "                                                     save_prefix='aug',\n",
    "                                                     save_format='jpeg')):\n",
    "                if i >= 3:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_path = base_dir + \"train_augmented\"\n",
    "dispaly_data_distribuation(train_augmented_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
